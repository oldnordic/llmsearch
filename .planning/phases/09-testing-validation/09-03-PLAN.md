---
phase: 09-testing-validation
plan: 03
type: execute
depends_on: []
files_modified: [tests/determinism.rs]
autonomous: true
---

<objective>
Create determinism verification tests.

Purpose: Verify that same inputs produce identical ordered outputs across multiple runs.
Output: New tests/determinism.rs file for determinism testing
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/main.rs
@.planning/phases/07-deterministic-ordering/07-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create determinism test file</name>
  <files>tests/determinism.rs</files>
  <action>Create tests/determinism.rs for determinism verification:

```rust
use assert_cmd::Command;
use serde_json::Value;

#[test]
fn test_determinism_same_inputs_same_outputs() {
    let temp_dir = std::env::temp_dir();

    // Create consistent test file
    let test_file = temp_dir.join("determinism_test.txt");
    let content = "line one\nline two\nline three\nline one\nline two";
    std::fs::write(&test_file, content).unwrap();

    // Run same search twice and compare outputs
    let output1 = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("line two")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    let output2 = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("line two")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    // Outputs should be identical
    assert_eq!(output1, output2, "Same inputs should produce identical JSON output");

    // Cleanup
    std::fs::remove_file(&test_file).unwrap();
}

#[test]
fn test_determinism_sorting_consistency() {
    let temp_dir = std::env::temp_dir();

    // Create multiple files with matches in different order
    let file_b = temp_dir.join("b.txt");
    let file_a = temp_dir.join("a.txt");
    std::fs::write(&file_b, "match in b\nmatch in b").unwrap();
    std::fs::write(&file_a, "match in a\nmatch in a").unwrap();

    let json_output = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("match")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    let output: Value = serde_json::from_str(&json_output).unwrap();
    let matches = output["matches"].as_array().unwrap();

    // Should have 4 matches total, sorted by file path then byte offset
    assert_eq!(matches.len(), 4);

    // First two should be from a.txt (alphabetically before b.txt)
    assert!(matches[0]["file"].as_str().unwrap().ends_with("a.txt"));
    assert!(matches[1]["file"].as_str().unwrap().ends_with("a.txt"));

    // Last two should be from b.txt
    assert!(matches[2]["file"].as_str().unwrap().ends_with("b.txt"));
    assert!(matches[3]["file"].as_str().unwrap().ends_with("b.txt"));

    // Within same file, byte offsets should be ascending
    assert!(matches[0]["byte_start"].as_u64().unwrap() < matches[1]["byte_start"].as_u64().unwrap());
    assert!(matches[2]["byte_start"].as_u64().unwrap() < matches[3]["byte_start"].as_u64().unwrap());

    // Cleanup
    std::fs::remove_file(&file_b).unwrap();
    std::fs::remove_file(&file_a).unwrap();
}
```

Tests verify:
- Same inputs produce byte-for-byte identical JSON
- Sorting is consistent: file path first, then byte offset
- Multiple runs produce same match_id values (note: match_id is random UUID, but order should be deterministic by file/byte)
</action>
  <verify>`cargo test test_determinism` passes both tests</verify>
  <done>Determinism tests verify consistent ordering</done>
</task>

<task type="auto">
  <name>Task 2: Add execution_id uniqueness test</name>
  <files>tests/determinism.rs</files>
  <action>Add test for execution_id uniqueness across runs:

```rust
#[test]
fn test_execution_id_unique_per_run() {
    let temp_dir = std::env::temp_dir();

    let test_file = temp_dir.join("exec_id_test.txt");
    std::fs::write(&test_file, "test content").unwrap();

    let output1 = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("test")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    let output2 = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("test")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    let json1: Value = serde_json::from_str(&output1).unwrap();
    let json2: Value = serde_json::from_str(&output2).unwrap();

    let exec_id1 = json1["execution_id"].as_str().unwrap();
    let exec_id2 = json2["execution_id"].as_str().unwrap();

    // Execution IDs should be unique (UUID v4)
    assert_ne!(exec_id1, exec_id2, "Each run should have unique execution_id");

    // Both should be valid UUIDs
    assert!(uuid::Uuid::parse_str(exec_id1).is_ok());
    assert!(uuid::Uuid::parse_str(exec_id2).is_ok());

    // Cleanup
    std::fs::remove_file(&test_file).unwrap();
}
```

Tests verify:
- Each execution generates unique execution_id
- execution_id format is valid UUID v4
- Multiple runs are independently identifiable
</action>
  <verify>`cargo test test_execution_id_unique_per_run` passes</verify>
  <done>Execution ID uniqueness verified</done>
</task>

<task type="auto">
  <name>Task 3: Add limit determinism test</name>
  <files>tests/determinism.rs</files>
  <action>Add test for limit functionality consistency:

```rust
#[test]
fn test_limit_returns_first_n_sorted() {
    let temp_dir = std::env::temp_dir();

    // Create files with many matches
    let test_file = temp_dir.join("limit_test.txt");
    let content = "match\nmatch\nmatch\nmatch\nmatch\nmatch\nmatch\nmatch\nmatch\nmatch";
    std::fs::write(&test_file, content).unwrap();

    // Request limit of 5
    let json_output = Command::cargo_bin("llmsearch")
        .arg("-r")
        .arg(temp_dir.to_str().unwrap())
        .arg("-p")
        .arg("match")
        .arg("-l")
        .arg("5")
        .arg("--json")
        .output()
        .unwrap()
        .stdout;

    let output: Value = serde_json::from_str(&json_output).unwrap();

    // Should have exactly 5 matches
    assert_eq!(output["match_count"].as_u64().unwrap(), 5);
    assert_eq!(output["matches"].as_array().unwrap().len(), 5);

    // All matches should be from same file (only one file exists)
    for m in output["matches"].as_array().unwrap() {
        assert!(m["file"].as_str().unwrap().ends_with("limit_test.txt"));
    }

    // Byte offsets should be ascending (deterministic ordering)
    let mut prev_byte = 0;
    for m in output["matches"].as_array().unwrap() {
        let byte = m["byte_start"].as_u64().unwrap();
        assert!(byte >= prev_byte, "Byte offsets should be ascending");
        prev_byte = byte;
    }

    // Cleanup
    std::fs::remove_file(&test_file).unwrap();
}
```

Tests verify:
- Limit truncates to exact number requested
- Returns first N after sorting
- Within sorted results, ordering is preserved
</action>
  <verify>`cargo test test_limit_returns_first_n_sorted` passes</verify>
  <done>Limit determinism verified</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cargo test` compiles all determinism tests
- [ ] test_determinism_same_inputs_same_outputs passes
- [ ] test_determinism_sorting_consistency passes
- [ ] test_execution_id_unique_per_run passes
- [ ] test_limit_returns_first_n_sorted passes
- [ ] All tests run clean
</verification>

<success_criteria>

- Determinism test file created with 4 tests
- Same inputs produce identical outputs verified
- Sorting consistency (file then byte) verified
- Execution ID uniqueness verified
- Limit determinism verified
- Phase 9 complete: comprehensive test suite
  </success_criteria>

<output>
After completion, create `.planning/phases/09-testing-validation/09-03-SUMMARY.md`
</output>
